#!/usr/bin/env python3
"""
Working verification script that properly parses your train.txt format
"""

import numpy as np
import re
import os
import sys


def parse_train_file(filepath):
    """Parse your specific train.txt format"""
    print(f"\nüìÑ Reading {filepath}...")

    try:
        with open(filepath, 'r') as f:
            content = f.read()
    except FileNotFoundError:
        print(f"‚ùå Could not find {filepath}")
        return []

    # Split by the long separator lines
    sections = content.split('='*80)

    configurations = []

    for section in sections:
        if 'RUN' not in section or 'Success: True' not in section:
            continue

        # Extract RUN number
        run_match = re.search(r'RUN (\d+):', section)
        if not run_match:
            continue
        run_num = run_match.group(1)

        # Extract description
        desc_match = re.search(r'Description: (.*?)\n', section)
        description = desc_match.group(1) if desc_match else f"RUN {run_num}"

        # Extract the lattice - look for the specific pattern in Modified Parameters
        if 'Modified Parameters:' in section:
            # Find the core_lattice line and everything until the next parameter or Success
            lattice_match = re.search(r'core_lattice:\s*\[(.*?)\]\s*(?:Success:|$)', section, re.DOTALL)
            if not lattice_match:
                continue

            lattice_text = lattice_match.group(1)

            # Parse the nested array structure
            # Remove newlines and extra spaces
            lattice_text = lattice_text.replace('\n', ' ').replace('\r', '')

            # Find all the row arrays
            row_pattern = r'\[([^\[\]]+)\]'
            rows = re.findall(row_pattern, lattice_text)

            if len(rows) != 8:
                continue

            # Parse each row
            lattice = []
            for row_str in rows:
                # Split by comma and clean each cell
                cells = []
                for cell in row_str.split(','):
                    cell = cell.strip().strip("'").strip('"')
                    if cell:
                        cells.append(cell)

                if len(cells) == 8:
                    lattice.append(cells)

            if len(lattice) != 8:
                continue

            lattice = np.array(lattice)

        else:
            continue

        # Extract flux values
        flux_dict = {}
        flux_matches = re.findall(r'(I_\d+) Flux ([\d.e+]+)', section)
        for label, flux_str in flux_matches:
            flux_dict[label] = float(flux_str)

        if len(flux_dict) != 4:
            continue

        configurations.append({
            'run': run_num,
            'description': description,
            'lattice': lattice,
            'flux': flux_dict
        })

    return configurations


def analyze_configuration(config):
    """Analyze a single configuration for the flux ordering bug"""
    lattice = config['lattice']
    flux_dict = config['flux']

    # Find irradiation positions
    positions = []
    for i in range(lattice.shape[0]):
        for j in range(lattice.shape[1]):
            if lattice[i, j].startswith('I'):
                positions.append((i, j, lattice[i, j]))

    # Sort spatially (by position)
    spatial_order = sorted(positions, key=lambda x: (x[0], x[1]))
    spatial_labels = [p[2] for p in spatial_order]

    # Sort alphabetically (by label)
    alpha_labels = sorted(flux_dict.keys())

    # Check if they differ
    is_affected = spatial_labels != alpha_labels

    return {
        'is_affected': is_affected,
        'spatial_order': spatial_order,
        'spatial_labels': spatial_labels,
        'alpha_labels': alpha_labels,
        'positions': positions
    }


def main():
    """Main verification function"""
    print("\n" + "="*80)
    print("FLUX ORDERING BUG VERIFICATION")
    print("Working Parser for Your Data")
    print("="*80)

    # Find the data file
    data_paths = [
        'ML/data/train.txt',
        'data/train.txt',
        '../ML/data/train.txt',
        'train.txt'
    ]

    data_file = None
    for path in data_paths:
        if os.path.exists(path):
            data_file = path
            break

    if not data_file:
        print("\n‚ùå Could not find train.txt")
        print("Please run from your project directory")
        return

    # Parse configurations
    configs = parse_train_file(data_file)

    if not configs:
        print("\n‚ùå Could not parse any configurations")
        print("Please check the file format")
        return

    print(f"\n‚úÖ Successfully parsed {len(configs)} configurations")

    # Analyze each configuration
    affected_count = 0
    examples = []

    for config in configs:
        analysis = analyze_configuration(config)

        if analysis['is_affected']:
            affected_count += 1
            if len(examples) < 3:  # Keep first 3 examples
                examples.append((config, analysis))

    # Show statistics
    print("\n" + "="*80)
    print("STATISTICS")
    print("="*80)

    print(f"\nTotal configurations: {len(configs)}")
    print(f"Affected by bug: {affected_count}")
    print(f"Percentage affected: {affected_count/len(configs)*100:.1f}%")

    # Show examples
    if examples:
        print("\n" + "="*80)
        print("CONCRETE EXAMPLES")
        print("="*80)

        for config, analysis in examples[:2]:  # Show 2 examples
            print(f"\n" + "-"*70)
            print(f"RUN {config['run']}: {config['description']}")
            print("-"*70)

            lattice = config['lattice']
            flux_dict = config['flux']

            # Show lattice
            print("\nReactor Configuration:")
            for i in range(8):
                row_str = ""
                for j in range(8):
                    cell = lattice[i, j]
                    if cell.startswith('I'):
                        flux = flux_dict[cell] / 1e14
                        if i in [0, 7] or j in [0, 7]:
                            row_str += f"[{cell}:{flux:.2f}]"
                        else:
                            row_str += f" {cell}:{flux:.2f} "
                    else:
                        row_str += f"  {cell}   "
                print(row_str)

            print("\n[brackets] = edge position")

            # Show the bug
            print(f"\n‚ùå BUGGY (Alphabetical): {analysis['alpha_labels']}")
            alpha_flux = [flux_dict[l]/1e14 for l in analysis['alpha_labels']]
            print(f"   Flux: [{', '.join(f'{f:.2f}' for f in alpha_flux)}]")

            print(f"\n‚úÖ FIXED (Spatial): {analysis['spatial_labels']}")
            print(f"   Positions: {[f'({p[0]},{p[1]})' for p in analysis['spatial_order']]}")
            spatial_flux = [flux_dict[l]/1e14 for l in analysis['spatial_labels']]
            print(f"   Flux: [{', '.join(f'{f:.2f}' for f in spatial_flux)}]")

            # Show mismatches
            print("\n‚ö†Ô∏è  MISLEARNING:")
            for idx in range(4):
                if analysis['spatial_labels'][idx] != analysis['alpha_labels'][idx]:
                    pos = analysis['spatial_order'][idx]
                    spatial_label = analysis['spatial_labels'][idx]
                    alpha_label = analysis['alpha_labels'][idx]

                    print(f"   Position {idx} at {pos[0:2]}:")
                    print(f"     Model learns: {alpha_label} flux ({flux_dict[alpha_label]/1e14:.2f})")
                    print(f"     Should learn: {spatial_label} flux ({flux_dict[spatial_label]/1e14:.2f})")

    # Final summary
    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)

    if affected_count > 0:
        print(f"\nüö® CRITICAL BUG CONFIRMED!")
        print(f"   {affected_count} out of {len(configs)} configurations ({affected_count/len(configs)*100:.0f}%)")
        print(f"   are teaching your model WRONG spatial-flux relationships!")

        print("\nüìä Your current results (R¬≤ = 0.7555) are misleading because:")
        print("   ‚Ä¢ Model memorizes label patterns instead of spatial physics")
        print("   ‚Ä¢ Cannot learn that edge ‚Üí low flux, center ‚Üí high flux")
        print("   ‚Ä¢ Will fail on new configurations")

        print("\nüîß Apply these fixes immediately:")
        print("   1. Fix flux ordering in data_handler.py (spatial not alphabetical)")
        print("   2. Update encodings to track position identity")
        print("   3. Fix augmentation rotation formula")
        print("   4. Retrain all models")

        print("\nüöÄ Expected improvement: SIGNIFICANT")
        print("   This is a fundamental bug destroying spatial learning!")
    else:
        print("\n‚úÖ No flux ordering issues found")
        print("   (All configurations have matching alphabetical and spatial orders)")

    print("\n" + "="*80)


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
